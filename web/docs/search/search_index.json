{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>AAOS means Analysis, Automation and Orchestration System. AAOS is a cloud native web application based on Django Rest Framework for different workloads, developed by Ceruno AG.</p>"},{"location":"#workloads","title":"Workloads","text":""},{"location":"#data-exports","title":"Data Exports","text":"<p>Export data fetched from an API as json objects to a data lake from sources like SentinelOne, Jira, Freshservice or Postgres to Elastic, Grafana Loki or DataSet (SentinelOne).</p>"},{"location":"#data-analysis","title":"Data Analysis","text":"<p>Analyse the Activity stream of SentinelOne e.g create an alert if a an update request was sent to an agent and the update did not succeed between the next 60 minutes.</p>"},{"location":"#licensing-monitoring","title":"Licensing Monitoring","text":"<p>Monitor the license usage and expiration dates of SentinelOne. Conditionally create or update corresponding Jira issues or Freshservice tickets.</p>"},{"location":"architecture/","title":"Architecture","text":"<p>AAOS is built with Django REST Framework and Celery - Distributed Task Queue with Flower and django-celery-beat. It's using Postgres as DB, Redis as broker and NGINX to server the static files. </p> <p></p>"},{"location":"endpoints/","title":"Endpoints","text":"<p>If you browse this documentation directly on AAOS you can use this direct links.</p> MainConfigurationExportsAnalyticsLicensing <p>Bexio Freshservice Jira Postgres SentinelOne </p> <p>SentinelOne </p> <p>SentinelOne </p>"},{"location":"endpoints/#aggregators","title":"Aggregators","text":"<p>Configuration Exports Analytics Licensing</p>"},{"location":"endpoints/#users","title":"Users","text":"<p>Users</p>"},{"location":"endpoints/#api","title":"API","text":"<p>OpenAPI Swagger UI</p>"},{"location":"endpoints/#connectors","title":"Connectors","text":"<p>Bexio DataSet Elastic Freshservice Jira Loki Postgres SentinelOne SharePoint </p>"},{"location":"endpoints/#workloads","title":"Workloads","text":"<p>Crontab Schedule Interval Schedule Tasks </p>"},{"location":"install/","title":"Install","text":"<p>Use TLS</p> <p>This installation routine does not provide any TLS configuration. We strongly recommend putting the endpoints behind a reverse proxy or web application firewall.</p>"},{"location":"install/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker</li> <li>Docker Compose</li> </ul>"},{"location":"install/#from-github","title":"From GitHub","text":"<p>First clone the repository from github</p> <pre><code>git clone https://github.com/ceruno/aaos.git\n</code></pre> <p>Create a .env file from the template</p> <pre><code>cd aaos\nmkdir .env\ncp .env.example ./.env/.prod\n</code></pre> <p>Run the installer. This will create the db and tables in postgres and the admin user</p> <pre><code>./install.sh\n</code></pre>"},{"location":"install/#from-docker-hub","title":"From Docker Hub","text":"<p>create an <code>.env</code> file</p> <pre><code>SECRET_KEY=''\nDJANGO_ALLOWED_HOSTS=*\nDJANGO_SUPERUSER_USERNAME=admin\nDJANGO_SUPERUSER_PASSWORD=''\nDJANGO_SUPERUSER_EMAIL=''\nENCRYPTION_KEY=''\n\nSQL_ENGINE=django.db.backends.postgresql\nSQL_DATABASE=aaos\nSQL_USER=aaos\nSQL_PASSWORD=''\nSQL_HOST=db\nSQL_PORT=5432\n\nPOSTGRES_DB=aaos\nPOSTGRES_USER=aaos\nPOSTGRES_PASSWORD=''\n\nCELERY_BROKER=redis://broker:6379/0\nCELERY_BACKEND=redis://broker:6379/0\n\nELASTIC_APM_SERVICE_NAME=aaos\nELASTIC_APM_VERIFY_SERVER_CERT=True\nELASTIC_APM_LOG_LEVEL=error\nELASTIC_APM_DEBUG=False\nELASTIC_APM_SERVER_URL=\n</code></pre> <p>create a file called <code>docker-compose.yml</code> in the same directory</p> <pre><code>version: '3.4'\nservices:\napi:\nimage: ceruno/aaos\nports:\n- 8000:8000\nenv_file:\n- .env\ndepends_on:\n- broker\n- db\ndb:\nimage: postgres:15-alpine\nvolumes:\n- db_data:/var/lib/postgresql/data/\nenv_file:\n- .env\nbroker:\nimage: redis:7-alpine\nworker:\nimage: ceruno/aaos\ncommand: [\"celery\", \"-A\", \"api\", \"worker\", \"--loglevel=info\"]\nenv_file:\n- .env\ndepends_on:\n- broker\nscheduler:\nimage: ceruno/aaos\ncommand: [\"celery\", \"-A\", \"api\", \"beat\", \"--loglevel=info\", \"--scheduler\", \"django_celery_beat.schedulers:DatabaseScheduler\"]\nenv_file:\n- .env\ndepends_on:\n- broker\nmonitor:\nimage: ceruno/aaos\nports:\n- 5555:5555\ncommand: [\"celery\", \"-A\", \"api\", \"flower\", \"--port=5555\"]\nenv_file:\n- .env\ndepends_on:\n- broker\nweb:\nimage: ceruno/aaos-web\nports:\n- 80:80\ndepends_on:\n- api\nvolumes:\ndb_data:\n</code></pre> <p>Start the containers, create the database and the superuser</p> <pre><code>docker compose up -d\ndocker exec aaos-api-1 python manage.py makemigrations config\ndocker exec aaos-api-1 python manage.py migrate\ndocker exec aaos-api-1 python manage.py createsuperuser --noinput\n</code></pre>"},{"location":"analytics/sentinelone/","title":"SentinelOne","text":"<p>This function fetches activities information from the SentinelOne management console.</p> <p>Endpoint</p> <pre><code>GET /analytics/s1\n</code></pre>"},{"location":"analytics/sentinelone/#update","title":"Update","text":"<p>Alpha</p> <p>This feature is not yet production ready.</p> <p>To check for unsuccessful updates, the job item is <code>update</code>.</p> <p>Example</p> <pre><code>{\n\"item\": \"update\"\n}\n</code></pre>"},{"location":"config/","title":"Configuration","text":""},{"location":"config/#connectors-workloads","title":"Connectors &amp; Workloads","text":"<p>To create some workloads you need to configure some connectors first. The <code>config</code> endpoint aggregates the available connectors and also the available settings to schedule any of the available workloads.</p> <p>Endpoint</p> <pre><code>GET /config/\n</code></pre>"},{"location":"config/#users","title":"Users","text":"<p>In case you want to create additional users use the <code>users</code> endpoint.</p> <p>Endpoint</p> <p>The users endpoint contains the user and group settings.</p> <pre><code>GET /users/\n</code></pre>"},{"location":"config/connectors/","title":"Connectors","text":"<p>In this section the connection parameters for the different services are configured. The input parameters are normally self-describing. However there might be some additional information.</p>"},{"location":"config/connectors/#bexio","title":"Bexio","text":"<p>Alpha</p> <p>This feature is not yet production ready.</p> <p>Endpoint</p> <pre><code>GET /config/bexio\n</code></pre>"},{"location":"config/connectors/#dataset","title":"DataSet","text":"<p>Endpoint</p> <pre><code>GET /config/dataset\n</code></pre>"},{"location":"config/connectors/#elastic","title":"Elastic","text":"<p>Endpoint</p> <pre><code>GET /config/elastic\n</code></pre>"},{"location":"config/connectors/#loki","title":"Loki","text":"<p>Endpoint</p> <pre><code>GET /config/loki\n</code></pre>"},{"location":"config/connectors/#freshservice","title":"Freshservice","text":"<p>Endpoint</p> <pre><code>GET /config/fresh\n</code></pre>"},{"location":"config/connectors/#jira","title":"Jira","text":"<p>Endpoint</p> <pre><code>GET /config/jira\n</code></pre>"},{"location":"config/connectors/#postgres","title":"Postgres","text":"<p>Endpoint</p> <pre><code>GET /config/postgres\n</code></pre>"},{"location":"config/connectors/#sentinelone","title":"Sentinelone","text":"<p>Endpoint</p> <pre><code>GET /config/s1\n</code></pre>"},{"location":"config/connectors/#sharepoint","title":"SharePoint","text":"<p>Alpha</p> <p>This feature is not yet production ready.</p> <p>Endpoint</p> <pre><code>GET /config/sharepoint\n</code></pre>"},{"location":"config/users/","title":"Users","text":"<p>Endpoint</p> <pre><code>GET /users/users\n</code></pre>"},{"location":"config/users/#groups","title":"Groups","text":"<p>Endpoint</p> <pre><code>GET /users/groups\n</code></pre>"},{"location":"config/workloads/","title":"Workloads","text":""},{"location":"config/workloads/#schedules","title":"Schedules","text":""},{"location":"config/workloads/#crontab","title":"Crontab","text":"<p>Endpoint</p> <pre><code>GET /config/crontabschedule\n</code></pre>"},{"location":"config/workloads/#interval","title":"Interval","text":"<p>Endpoint</p> <pre><code>GET /config/intervalschedule\n</code></pre>"},{"location":"config/workloads/#tasks","title":"Tasks","text":"<p>Endpoint</p> <pre><code>GET /config/periodictask\n</code></pre>"},{"location":"exports/","title":"Exports","text":"<p>Every export workload can be executed on demand. The <code>exports</code> endpoint aggregates the available workloads.</p> <p>Endpoint</p> <pre><code>GET /exports/\n</code></pre>"},{"location":"exports/bexio/","title":"Bexio","text":"<p>This function fetches different informations from Bexio.</p> <p>Endpoint</p> <pre><code>GET /exports/bexio\n</code></pre>"},{"location":"exports/bexio/#update","title":"Update","text":"<p>Alpha</p> <p>This feature is not yet production ready.</p> <p>To update specific Bexio items in SharePoint, the job item is <code>update</code>.</p> <p>Example</p> <pre><code>{\n\"item\": \"update\"\n}\n</code></pre>"},{"location":"exports/freshservice/","title":"Freshservice","text":"<p>This function fetches all the information from a Freshservice endpoint like <code>/api/v2/tickets</code> and exports it to any configured connector (Elastic, Grafana Loki, DataSet).</p> <p>Endpoint</p> <pre><code>GET /exports/fresh\n</code></pre>"},{"location":"exports/freshservice/#tickets","title":"Tickets","text":"<p>To export all tickets, the job item is <code>tickets</code>. If you configured an Elastic connector you must set the index in which the data should be stored.  Optionally you can set the Elastic pipeline to process the data further.</p> <p>Example</p> <pre><code>{\n\"item\": \"tickets\",\n\"index\": \"fresh-tickets\",\n\"pipeline\": \"fresh-tickets-pipeline\"\n}\n</code></pre>"},{"location":"exports/jira/","title":"Jira","text":"<p>This function fetches all the information from a Jira endpoint like <code>/rest/api/3/search</code> and exports it to any configured connector (Elastic, Grafana Loki, DataSet).</p> <p>Endpoint</p> <pre><code>GET /exports/jira\n</code></pre>"},{"location":"exports/jira/#issues","title":"Issues","text":"<p>To export all issues, the job item is <code>issues</code>. Use wether a jql query or a specific project. If you configured an Elastic connector you must set the index in which the data should be stored.  Optionally you can set the Elastic pipeline to process the data further.</p> <p>Example</p> <pre><code>{\n\"item\": \"issues\",\n\"jql\": \"\",\n\"project\": \"updated &gt;= -30d AND project != TEMPL\",\n\"index\": \"jira-issues\",\n\"pipeline\": \"jira-issues-pipeline\"\n}\n</code></pre>"},{"location":"exports/postgres/","title":"Postgres","text":"<p>This function fetches all the information from a Postgres Database and exports it to any configured connector (Elastic, Grafana Loki, DataSet).</p> <p>Endpoint</p> <pre><code>GET /exports/postgres\n</code></pre>"},{"location":"exports/postgres/#table","title":"Table","text":"<p>Example</p> <pre><code>{\n\"item\": \"table\",\n\"query\": \"SELECT * FROM public.Table\",\n\"index\": \"postgres-data\",\n\"pipeline\": \"\"\n}\n</code></pre>"},{"location":"exports/sentinelone/","title":"SentinelOne","text":"<p>This function fetches all the information from a SentinelOne endpoint like <code>/web/api/v2.1/agents</code> and exports it to any configured connector (Elastic, Grafana Loki, DataSet).</p> <p>Endpoint</p> <pre><code>GET /exports/s1\n</code></pre>"},{"location":"exports/sentinelone/#agents","title":"Agents","text":"<p>To export all agents, the job item is <code>agents</code>. If you configured an Elastic connector you must set the index in which the data should be stored.  Optionally you can set the Elastic pipeline to process the data further.</p> <p>Example</p> <pre><code>{\n\"item\": \"agents\",\n\"index\": \"sentinelone-agents\",\n\"pipeline\": \"sentinelone-agents-pipeline\",\n\"limit\": \"\",\n\"timedelta\": \"\"\n}\n</code></pre>"},{"location":"exports/sentinelone/#activities","title":"Activities","text":"<p>To export all activities, the job item is <code>activities</code>. If you configured an Elastic connector you must set the index in which the data should be stored.  Optionally you can set the Elastic pipeline to process the data further.</p> <p>Example</p> <pre><code>{\n\"item\": \"activities\",\n\"index\": \"sentinelone-activities\",\n\"pipeline\": \"\",\n\"limit\": \"\",\n\"timedelta\": \"2\"\n}\n</code></pre>"},{"location":"licensing/sentinelone/","title":"SentinelOne","text":"<p>This function fetches all the licensing information from SentinelOne accounts and sites.</p> <p>Endpoint</p> <pre><code>GET /licensing/s1\n</code></pre>"},{"location":"licensing/sentinelone/#expiration","title":"Expiration","text":"<p>The expiration function discovers accounts and sites below the threshold and creates or updates therefore Jira issues or Freshservice tickets.</p> <p>Threshold</p> <p>The thresholds are currently hard coded and set to <code>30 days</code>.  </p> <p>To check for the expiration, the job item is <code>expiration</code>. Use <code>jira</code> or <code>fresh</code> as target. The project key is used for <code>jira</code> only and case sensitive.</p> <p>Example</p> <pre><code>{\n\"item\": \"expiration\",\n\"target\": \"jira\",\n\"project\": \"SENTINELONE\"\n}\n</code></pre>"},{"location":"licensing/sentinelone/#usage","title":"Usage","text":"<p>The usage function discovers accounts and sites above the threshold and creates or updates therefore Jira issues or Freshservice tickets.</p> <p>Threshold</p> <p>The thresholds are currently hard coded and set to:  </p> <ul> <li>Overprovisioning is larger than <code>5%</code> but at least <code>10 agents</code>.  </li> <li>Overprovisioning is larger than <code>100 agents</code>.</li> </ul> <p>To check for the usage, the job item is <code>usage</code>. Use <code>jira</code> or <code>fresh</code> as destination. The project key is used for <code>jira</code> only and case sensitive.</p> <p>Example</p> <pre><code>{\n\"item\": \"usage\",\n\"target\": \"jira\",\n\"project\": \"SENTINELONE\"\n}\n</code></pre>"}]}